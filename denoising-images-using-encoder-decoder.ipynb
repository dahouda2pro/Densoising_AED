{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport zipfile\nimport os\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, Conv2DTranspose, Input\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-24T01:58:38.984550Z","iopub.execute_input":"2022-02-24T01:58:38.985140Z","iopub.status.idle":"2022-02-24T01:58:45.015324Z","shell.execute_reply.started":"2022-02-24T01:58:38.985038Z","shell.execute_reply":"2022-02-24T01:58:45.009843Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# path to zipped & working directories\npath_zip = '/kaggle/input/denoising-dirty-documents/'\npath = '/kaggle/working/'\n\n# unzip files first to working directory\n# We could use also unzipped data source, but why not to learn something new?\nwith zipfile.ZipFile(path_zip + 'train.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)\n\nwith zipfile.ZipFile(path_zip + 'test.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'train_cleaned.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'sampleSubmission.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  ","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:05:20.422113Z","iopub.execute_input":"2021-12-17T06:05:20.422784Z","iopub.status.idle":"2021-12-17T06:05:23.379722Z","shell.execute_reply.started":"2021-12-17T06:05:20.422739Z","shell.execute_reply":"2021-12-17T06:05:23.378634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# store image names in list for later use\ntrain_img = sorted(os.listdir(path + '/train'))\ntrain_cleaned_img = sorted(os.listdir(path + '/train_cleaned'))\ntest_img = sorted(os.listdir(path + '/test'))","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:05:23.381521Z","iopub.execute_input":"2021-12-17T06:05:23.382058Z","iopub.status.idle":"2021-12-17T06:05:23.39087Z","shell.execute_reply.started":"2021-12-17T06:05:23.382016Z","shell.execute_reply":"2021-12-17T06:05:23.38952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare function\ndef process_image(path):\n    img = cv2.imread(path)\n    img = np.asarray(img, dtype=\"float32\")\n    img = cv2.resize(img, (540, 420))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = img/255.0\n    img = np.reshape(img, (420, 540, 1))\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:05:23.393958Z","iopub.execute_input":"2021-12-17T06:05:23.394319Z","iopub.status.idle":"2021-12-17T06:05:23.402657Z","shell.execute_reply.started":"2021-12-17T06:05:23.394274Z","shell.execute_reply":"2021-12-17T06:05:23.401416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocess images\ntrain = []\ntrain_cleaned = []\ntest = []\n\nfor f in sorted(os.listdir(path + 'train/')):\n    train.append(process_image(path + 'train/' + f))\n\nfor f in sorted(os.listdir(path + 'train_cleaned/')):\n    train_cleaned.append(process_image(path + 'train_cleaned/' + f))\n   \nfor f in sorted(os.listdir(path + 'test/')):\n    test.append(process_image(path + 'test/' + f))","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:05:23.404349Z","iopub.execute_input":"2021-12-17T06:05:23.405521Z","iopub.status.idle":"2021-12-17T06:05:26.074052Z","shell.execute_reply.started":"2021-12-17T06:05:23.405424Z","shell.execute_reply":"2021-12-17T06:05:26.07308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train[i][:,:,0], cmap='gray')\n    plt.title('Noise image: {}'.format(train_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train_cleaned[i][:,:,0], cmap='gray')\n    plt.title('Denoised image: {}'.format(train_img[i]))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:05:26.076875Z","iopub.execute_input":"2021-12-17T06:05:26.077516Z","iopub.status.idle":"2021-12-17T06:05:27.252886Z","shell.execute_reply.started":"2021-12-17T06:05:26.077471Z","shell.execute_reply":"2021-12-17T06:05:27.251639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert list to numpy array\nX_train = np.asarray(train)\ny_train = np.asarray(train_cleaned)\nX_test = np.asarray(test)\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:05:27.25512Z","iopub.execute_input":"2021-12-17T06:05:27.256149Z","iopub.status.idle":"2021-12-17T06:05:27.497481Z","shell.execute_reply.started":"2021-12-17T06:05:27.256106Z","shell.execute_reply":"2021-12-17T06:05:27.496525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_autoencoder = Sequential()\n\n# Encoder\nconv_autoencoder.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(420,540,1), activation='relu', padding='same'))\nconv_autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n\nconv_autoencoder.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'))\nconv_autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n\n\n\n# Decoder\nconv_autoencoder.add(Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'))\nconv_autoencoder.add(Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'))\n\n\n# Output\nconv_autoencoder.add(Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same'))\n\nconv_autoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:05:27.499356Z","iopub.execute_input":"2021-12-17T06:05:27.499691Z","iopub.status.idle":"2021-12-17T06:05:30.706268Z","shell.execute_reply.started":"2021-12-17T06:05:27.499649Z","shell.execute_reply":"2021-12-17T06:05:30.705158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n\nearly_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\nhistory= conv_autoencoder.fit(X_train, y_train, validation_data = (X_val, y_val), epochs=50, batch_size=16, callbacks= [early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:05:30.708163Z","iopub.execute_input":"2021-12-17T06:05:30.708456Z","iopub.status.idle":"2021-12-17T06:06:53.816426Z","shell.execute_reply.started":"2021-12-17T06:05:30.708414Z","shell.execute_reply":"2021-12-17T06:06:53.815393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how loss & mae went down\nepoch_loss = history.history['loss']\nepoch_val_loss = history.history['val_loss']\nepoch_mae = history.history['mae']\nepoch_val_mae = history.history['val_mae']\n\nplt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nplt.plot(range(0,len(epoch_loss)), epoch_loss, 'b-', linewidth=2, label='Train Loss')\nplt.plot(range(0,len(epoch_val_loss)), epoch_val_loss, 'r-', linewidth=2, label='Val Loss')\nplt.title('Evolution of loss on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2)\nplt.plot(range(0,len(epoch_mae)), epoch_mae, 'b-', linewidth=2, label='Train MAE')\nplt.plot(range(0,len(epoch_val_mae)), epoch_val_mae, 'r-', linewidth=2,label='Val MAE')\nplt.title('Evolution of MAE on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:06:53.82031Z","iopub.execute_input":"2021-12-17T06:06:53.821795Z","iopub.status.idle":"2021-12-17T06:06:54.308251Z","shell.execute_reply.started":"2021-12-17T06:06:53.821748Z","shell.execute_reply":"2021-12-17T06:06:54.307272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = conv_autoencoder.predict(X_test, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:06:54.309701Z","iopub.execute_input":"2021-12-17T06:06:54.310444Z","iopub.status.idle":"2021-12-17T06:06:55.216049Z","shell.execute_reply.started":"2021-12-17T06:06:54.310395Z","shell.execute_reply":"2021-12-17T06:06:55.215026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_test[i][:,:,0], cmap='gray')\n    plt.title('Noisy image: {}'.format(test_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(y_pred[i][:,:,0], cmap='gray')\n    plt.title('Denoised by autoencoder: {}'.format(test_img[i]))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:06:55.217677Z","iopub.execute_input":"2021-12-17T06:06:55.218048Z","iopub.status.idle":"2021-12-17T06:06:56.221531Z","shell.execute_reply.started":"2021-12-17T06:06:55.217993Z","shell.execute_reply":"2021-12-17T06:06:56.220553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# it will take a while!\nids = []\nvals = []\nfor i, f in enumerate(test_img):\n    file = path + 'test/' + f\n    imgid = int(f[:-4])\n    img = cv2.imread(file, 0)\n    img_shape = img.shape\n    print('Processing image: {} \\tinto size: {}'.format(f, img_shape))    # uncomment to see progress\n    preds_reshaped = cv2.resize(y_pred[i], (img_shape[1], img_shape[0]))\n\n    for r in range(img_shape[0]):\n        for c in range(img_shape[1]):\n            ids.append(str(imgid)+'_'+str(r + 1)+'_'+str(c + 1))\n            vals.append(preds_reshaped[r, c])\n\nsubmission = pd.DataFrame({'id': ids, 'value': vals})\nsubmission.to_csv('submission.csv',index = False)\n\nprint('Results saved to submission.csv!')\n\n# quick check if length of IDs is OK\n# we should get there number 14230080\nprint('Length of IDs: {}'.format(len(ids)))","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:06:56.223059Z","iopub.execute_input":"2021-12-17T06:06:56.224735Z","iopub.status.idle":"2021-12-17T06:08:14.547344Z","shell.execute_reply.started":"2021-12-17T06:06:56.224689Z","shell.execute_reply":"2021-12-17T06:08:14.546295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check first few rows of submission\nmy_submission = pd.read_csv('submission.csv')\nmy_submission.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T06:08:14.548833Z","iopub.execute_input":"2021-12-17T06:08:14.549498Z","iopub.status.idle":"2021-12-17T06:08:23.222996Z","shell.execute_reply.started":"2021-12-17T06:08:14.549462Z","shell.execute_reply":"2021-12-17T06:08:23.222088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}